{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyOZEUP1obl/CPe0wYsi2qCq"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["**Giới thiệu**\n","\n","* Mô hình fask mask detection qua camera theo dõi hành vi đeo khẩu trang nơi công cộng.\n","\n","* Ngày này, có rất nhiều virus truyền nhiễm qua đường hô hấp khi giao tiếp. Đeo khẩu trang nhằm tạo ra rào cản khi giao tiếp  giúpngăn ngừa và bảo vệ người đeo khỏi bị lây nhiễm các loại vi khuẩn, vi-rút, bụi bặm thông qua đường hô hấp.\n","\n","*  Bộ dữ liệu được thu thập từ Kaggle: https://www.kaggle.com/datasets/andrewmvd/face-mask-detection?fbclid=IwY2xjawNJ-2JleHRuA2FlbQIxMQABHliTM7BPKg6MLRw_TwKuHo-w_NFd4Ic1H4LN3NBmPiwstLYPt4DuKijCELqk_aem_YfIg5F96RnGGx4aNknP2aA\n","\n","* Bộ dữ liệu gồm gần 1000 ảnh màu đươc chia thành 3 lớp: with_mask, without_mask và mask_weared_incorrect.\n","\n","\n"],"metadata":{"id":"jU4YwY241Vyg"}},{"cell_type":"markdown","source":["**Thư viện và tải dữ liệu**\n","\n","* google.colab.drive kết nối với google drive để lấy dữ liệu và ghi dữ liệu.\n","\n","* os cho phép tương tác với hệ điều hành, dùng để liệt kê các tệp ảnh, chú thích, nối các đường dẫn với nhau, tách tên têp ra khỏi đuôi, tạo thư mục mới.\n","\n","* cv2 chuyên sử lý thị giác máy tính , dùng để đọc tệp ảnh từ ổ đĩa, phát hiện các ảnh bị hỏng.\n","\n","* xml.etree.ElementTree được sử dụng cho việc đọc, phân tích các tệp định dạng xml, tìm các thẻ, lấy dữ liệu bên trong thẻ.\n","\n","* collections.Counter đếm số lần suất hiện các lớp.\n","\n","* shutil sao chép tệp từ thư mục gốc vào các thư mục chia.\n","\n","* sklearn.model_selecton -> train_test_split trong scikit-learn để chia bộ dữ liệu thành các mục train/val/test.\n","\n","* random chọn ngẫu nhiên tiệp từ danh sách gốc"],"metadata":{"id":"-nSF56F-fzvm"}},{"cell_type":"code","execution_count":5,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"trJm8ZmvUQ7I","executionInfo":{"status":"ok","timestamp":1762229616561,"user_tz":-420,"elapsed":24289,"user":{"displayName":"Bách Vũ Xuân","userId":"10483577199262630046"}},"outputId":"1b485267-cc29-4f1d-edce-48a83e14dc1f"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')\n"]},{"cell_type":"code","source":["!ls /content/drive/MyDrive/Face_mask_project\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"YOnCl2muWLh6","executionInfo":{"status":"ok","timestamp":1762184510024,"user_tz":-420,"elapsed":906,"user":{"displayName":"Bách Vũ Xuân","userId":"10483577199262630046"}},"outputId":"06e937b6-d8ba-4ab9-cd2c-18cfa64b0f13"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["data  face_mask.yaml  notebooks  results  runs\tyolo11n.pt  yolov8s.pt\n"]}]},{"cell_type":"code","source":["import os\n","import cv2\n","import xml.etree.ElementTree as ET\n","from collections import Counter\n","import shutil\n","from sklearn.model_selection import train_test_split\n","import random"],"metadata":{"id":"dQBIkFj3-a6C","executionInfo":{"status":"ok","timestamp":1762229894973,"user_tz":-420,"elapsed":43,"user":{"displayName":"Bách Vũ Xuân","userId":"10483577199262630046"}}},"execution_count":11,"outputs":[]},{"cell_type":"markdown","source":["**Phân tích, khám phá dữ liệu**\n","\n","* 853 ảnh màu, mỗi ảnh đều có annotation tương ứng.\n","\n","* Tất cả các ảnh đều đọc được.\n","\n","* 4072 object chia không đều vào các lớp, đây là một imbalance data.\n","\n","* Không có annotations nào bị lỗi. Một số bị over bouding box nhưng tỉ lệ rất nhỏ vẫn sử dụng đươc mà không bi ảnh hưởng.\n","\n","* Kích cỡ ảnh trung bình là 370.59 x 309.29 và kích cỡ bbox trung bình là 31.15 x 35.00."],"metadata":{"id":"uzXwNfv0-5-6"}},{"cell_type":"code","source":["BASE_DIR = '/content/drive/MyDrive/Face_mask_project'\n","DATA_DIR = f'{BASE_DIR}/data'\n","IMG_DIR  = f'{DATA_DIR}/images'\n","ANN_DIR  = f'{DATA_DIR}/annotations'\n","\n","print(\"BASE_DIR:\", BASE_DIR)\n","print(\"IMG_DIR:\", IMG_DIR)\n","print(\"ANN_DIR:\", ANN_DIR)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8vBrswRdWUaa","executionInfo":{"status":"ok","timestamp":1762229616609,"user_tz":-420,"elapsed":42,"user":{"displayName":"Bách Vũ Xuân","userId":"10483577199262630046"}},"outputId":"089b4a04-b0ac-4bd4-abaa-a904692c9487"},"execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["BASE_DIR: /content/drive/MyDrive/Face_mask_project\n","IMG_DIR: /content/drive/MyDrive/Face_mask_project/data/images\n","ANN_DIR: /content/drive/MyDrive/Face_mask_project/data/annotations\n"]}]},{"cell_type":"code","source":["image_files = sorted([f for f in os.listdir(IMG_DIR) if f.lower().endswith(('.jpg', '.jpeg', '.png'))])\n","anno_files  = sorted([f for f in os.listdir(ANN_DIR) if f.lower().endswith('.xml')])\n","\n","print(f\"Number of images: {len(image_files)}\")\n","print(f\"Number of annotations: {len(anno_files)}\")\n","\n","image_names = {os.path.splitext(f)[0] for f in image_files}\n","anno_names  = {os.path.splitext(f)[0] for f in anno_files}\n","\n","missing_annos = image_names - anno_names\n","missing_images = anno_names - image_names\n","\n","print(f\"Images without annotations: {len(missing_annos)}\")\n","print(f\"Annotations without images: {len(missing_images)}\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"p0WLStB-W8gl","executionInfo":{"status":"ok","timestamp":1762186890101,"user_tz":-420,"elapsed":221,"user":{"displayName":"Bách Vũ Xuân","userId":"10483577199262630046"}},"outputId":"3ed0702f-5b21-47b8-df6f-a9f2479af05c"},"execution_count":9,"outputs":[{"output_type":"stream","name":"stdout","text":["Number of images: 853\n","Number of annotations: 853\n","Images without annotations: 0\n","Annotations without images: 0\n"]}]},{"cell_type":"code","source":["broken_images = []\n","\n","for f in image_files:\n","    path = os.path.join(IMG_DIR, f)\n","    img = cv2.imread(path)\n","    if img is None:\n","        broken_images.append(f)\n","\n","print(f\"Number of broken images: {len(broken_images)}\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Qb6ghggPXqmk","executionInfo":{"status":"ok","timestamp":1761798930563,"user_tz":-420,"elapsed":121729,"user":{"displayName":"Bách Vũ Xuân","userId":"10483577199262630046"}},"outputId":"4d85408f-b1dd-4a89-84fb-db8fa9fb6f28"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Number of broken images: 0\n"]}]},{"cell_type":"code","source":["VALID_CLASSES = ['with_mask', 'without_mask', 'mask_weared_incorrect']\n","class_counter = Counter()\n","broken_annos, invalid_bbox_files = [], []\n","total_objects = total_img_count = total_bbox_count = 0\n","total_img_width = total_img_height = total_bbox_width = total_bbox_height = 0\n","\n","for f in anno_files:\n","    path = os.path.join(ANN_DIR, f)\n","    try:\n","        tree = ET.parse(path)\n","        root = tree.getroot()\n","        #parse XML\n","        size = root.find('size')\n","        if size is None:\n","            broken_annos.append(f\"Missing <size> tag: {f}\")\n","            continue\n","\n","        w, h = int(size.find('width').text), int(size.find('height').text)\n","        total_img_width += w\n","        total_img_height += h\n","        total_img_count += 1\n","\n","        objects = root.findall('object')\n","        if not objects:\n","            broken_annos.append(f\"No object tag: {f}\")\n","            continue\n","\n","        max_x_over = max_y_over = 0\n","        has_invalid_bbox = False\n","        invalid_classes = []\n","\n","        #classes\n","        for obj in objects:\n","            name = obj.find('name').text\n","            class_counter[name] += 1\n","            total_objects += 1\n","            if name not in VALID_CLASSES:\n","                invalid_classes.append(name)\n","\n","            #bounding-box\n","            b = obj.find('bndbox')\n","            xmin, ymin, xmax, ymax = map(int, [b.find(tag).text for tag in ('xmin', 'ymin', 'xmax', 'ymax')])\n","            bbox_w, bbox_h = xmax - xmin, ymax - ymin\n","            total_bbox_width += bbox_w\n","            total_bbox_height += bbox_h\n","            total_bbox_count += 1\n","\n","            #over bouding-box\n","            x_over = max(0, -xmin, xmax - w) / w * 100\n","            y_over = max(0, -ymin, ymax - h) / h * 100\n","            if x_over > 0 or y_over > 0:\n","                has_invalid_bbox = True\n","                max_x_over, max_y_over = max(max_x_over, x_over), max(max_y_over, y_over)\n","\n","        if invalid_classes:\n","            broken_annos.append(f\"Invalid class {invalid_classes} in file: {f}\")\n","        if has_invalid_bbox:\n","            invalid_bbox_files.append((f, max_x_over, max_y_over))\n","\n","    except Exception as e:\n","        broken_annos.append(f\"Error parsing {f}: {e}\")\n","\n","avg_bbox_w = total_bbox_width / total_bbox_count if total_bbox_count else 0\n","avg_bbox_h = total_bbox_height / total_bbox_count if total_bbox_count else 0\n","avg_img_w  = total_img_width / total_img_count if total_img_count else 0\n","avg_img_h  = total_img_height / total_img_count if total_img_count else 0\n","\n","print(f\"Total objects: {total_objects}\")\n","for cls, nb in class_counter.items():\n","    status = \"(VALID)\" if cls in VALID_CLASSES else \"(INVALID)\"\n","    print(f\"{cls}: {nb} {status}\")\n","\n","print(f\"\\n Broken annotations: {len(broken_annos)}\")\n","\n","print(f\"\\n Invalid bounding boxes: {len(invalid_bbox_files)}\")\n","for fname, x, y in invalid_bbox_files:\n","    print(f\" - {fname}: X exceed={x:.2f}%, Y exceed={y:.2f}%\")\n","\n","print(f\"\\n Average image size: {avg_img_w:.2f} x {avg_img_h:.2f}\")\n","print(f\" Average bounding box size: {avg_bbox_w:.2f} x {avg_bbox_h:.2f}\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"tWlxqZHJYdXT","executionInfo":{"status":"ok","timestamp":1762189896442,"user_tz":-420,"elapsed":4016,"user":{"displayName":"Bách Vũ Xuân","userId":"10483577199262630046"}},"outputId":"73e98eae-5c7f-4afd-ef9d-4bd0a7b1f796"},"execution_count":10,"outputs":[{"output_type":"stream","name":"stdout","text":["Total objects: 4072\n","without_mask: 717 (VALID)\n","with_mask: 3232 (VALID)\n","mask_weared_incorrect: 123 (VALID)\n","\n"," Broken annotations: 0\n","\n"," Invalid bounding boxes: 11\n"," - maksssksksss110.xml: X exceed=0.25%, Y exceed=0.00%\n"," - maksssksksss231.xml: X exceed=0.25%, Y exceed=0.00%\n"," - maksssksksss251.xml: X exceed=0.25%, Y exceed=0.00%\n"," - maksssksksss457.xml: X exceed=0.25%, Y exceed=0.00%\n"," - maksssksksss5.xml: X exceed=0.25%, Y exceed=0.00%\n"," - maksssksksss501.xml: X exceed=0.25%, Y exceed=0.00%\n"," - maksssksksss603.xml: X exceed=0.25%, Y exceed=0.00%\n"," - maksssksksss616.xml: X exceed=0.25%, Y exceed=0.00%\n"," - maksssksksss706.xml: X exceed=0.25%, Y exceed=0.00%\n"," - maksssksksss787.xml: X exceed=0.25%, Y exceed=0.00%\n"," - maksssksksss93.xml: X exceed=0.25%, Y exceed=0.00%\n","\n"," Average image size: 370.59 x 309.29\n"," Average bounding box size: 31.15 x 35.00\n"]}]},{"cell_type":"markdown","source":["**Preprocessing**\n","\n","* Chia dữ liệu thành 3 phần: 70% train, 20% val và 10% test.\n","\n","* Kiểm tra lại các dữ liệu đã chia.\n","\n","* Chuyển đổi dãn nhãn chứ thành dạng số.\n","\n","* Chuyển đổi dữ liệu ảnh sang txt để sủ dụng YOLO.\n","\n","* Oversample dữ liệu train giúp cân bằng dữ liệu, mô hình học tốt hơn."],"metadata":{"id":"vbH5ksP1uZmr"}},{"cell_type":"code","source":["TRAIN_RATIO = 0.7\n","VAL_RATIO   = 0.2\n","TEST_RATIO  = 0.1\n","SEED = 42\n","\n","pairs, labels = [], []\n","for xml_file in anno_files:\n","    base = os.path.splitext(xml_file)[0]\n","    for ext in ['.jpg', '.jpeg', '.png']:\n","        img_file = base + ext\n","        if img_file in image_files:\n","            pairs.append((img_file, xml_file))\n","            tree = ET.parse(os.path.join(ANN_DIR, xml_file))\n","            objs = tree.getroot().findall('object')\n","            labels.append(objs[0].find('name').text if objs else 'no_object')\n","            break\n","\n","#Split train+val/test\n","trainval, test, y_trainval, y_test = train_test_split(\n","    pairs, labels, test_size=TEST_RATIO, random_state=SEED, stratify=labels\n",")\n","#Split train/val\n","val_ratio_adj = VAL_RATIO / (1 - TEST_RATIO)\n","train, val, _, _ = train_test_split(\n","    trainval, y_trainval, test_size=val_ratio_adj, random_state=SEED, stratify=y_trainval\n",")\n","\n","#Copy files\n","for split_name, split_pairs in zip(['train','val','test'], [train,val,test]):\n","    img_out = os.path.join(DATA_DIR, split_name, 'images')\n","    ann_out = os.path.join(DATA_DIR, split_name, 'annotations')\n","    os.makedirs(img_out, exist_ok=True)\n","    os.makedirs(ann_out, exist_ok=True)\n","    for img_file, xml_file in split_pairs:\n","        shutil.copy(os.path.join(IMG_DIR, img_file), os.path.join(img_out, img_file))\n","        shutil.copy(os.path.join(ANN_DIR, xml_file), os.path.join(ann_out, xml_file))\n","\n","for split_name, split_pairs in zip(['train','val','test'], [train,val,test]):\n","    print(f\"{split_name}: {len(split_pairs)} pairs\")"],"metadata":{"id":"KFt65Dxrqgpc","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1762185659729,"user_tz":-420,"elapsed":147714,"user":{"displayName":"Bách Vũ Xuân","userId":"10483577199262630046"}},"outputId":"9f6f5de2-0f03-4504-8ace-d690dc7c2f99"},"execution_count":8,"outputs":[{"output_type":"stream","name":"stdout","text":["train: 596 pairs\n","val: 171 pairs\n","test: 86 pairs\n"]}]},{"cell_type":"code","source":["splits = ['train', 'val', 'test']\n","\n","for split in splits:\n","    ann_dir = os.path.join(DATA_DIR, split, 'annotations')\n","    class_counter = Counter()\n","    for xml_file in os.listdir(ann_dir):\n","        if not xml_file.lower().endswith('.xml'):\n","            continue\n","        tree = ET.parse(os.path.join(ann_dir, xml_file))\n","        root = tree.getroot()\n","        for obj in root.findall('object'):\n","            class_name = obj.find('name').text\n","            class_counter[class_name] += 1\n","    total_objects = sum(class_counter.values())\n","    print(f\"\\n{split.upper()}\")\n","    print(f\"Total objects: {total_objects}\")\n","    for cls, count in class_counter.items():\n","        print(f\"{cls}: {count}\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"681vhGxQrqnf","executionInfo":{"status":"ok","timestamp":1762190822286,"user_tz":-420,"elapsed":20598,"user":{"displayName":"Bách Vũ Xuân","userId":"10483577199262630046"}},"outputId":"7c4e3545-788f-44c0-c8d6-d02b574a4622"},"execution_count":11,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","TRAIN\n","Total objects: 3770\n","without_mask: 663\n","with_mask: 3000\n","mask_weared_incorrect: 107\n","\n","VAL\n","Total objects: 1481\n","without_mask: 241\n","with_mask: 1197\n","mask_weared_incorrect: 43\n","\n","TEST\n","Total objects: 650\n","with_mask: 513\n","without_mask: 113\n","mask_weared_incorrect: 24\n"]}]},{"cell_type":"code","source":["def check_dataset(img_dir, ann_dir):\n","    image_files = sorted([f for f in os.listdir(img_dir) if f.lower().endswith(('.jpg','.jpeg','.png'))])\n","    anno_files  = sorted([f for f in os.listdir(ann_dir) if f.lower().endswith('.xml')])\n","\n","    image_names = {os.path.splitext(f)[0] for f in image_files}\n","    anno_names  = {os.path.splitext(f)[0] for f in anno_files}\n","\n","    missing_annos = image_names - anno_names\n","    missing_images = anno_names - image_names\n","\n","    print(f\"Folder: {img_dir}\")\n","    print(f\"Images without annotations: {len(missing_annos)}\")\n","    print(f\"Annotations without images: {len(missing_images)}\")\n","\n","check_dataset(os.path.join(DATA_DIR,'train/images'), os.path.join(DATA_DIR,'train/annotations'))\n","check_dataset(os.path.join(DATA_DIR,'val/images'),   os.path.join(DATA_DIR,'val/annotations'))\n","check_dataset(os.path.join(DATA_DIR,'test/images'),  os.path.join(DATA_DIR,'test/annotations'))\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"UP2hjzoVQE5p","executionInfo":{"status":"ok","timestamp":1762229762971,"user_tz":-420,"elapsed":6840,"user":{"displayName":"Bách Vũ Xuân","userId":"10483577199262630046"}},"outputId":"9f59ad48-d43b-4559-9414-9f1523309c32"},"execution_count":10,"outputs":[{"output_type":"stream","name":"stdout","text":["Folder: /content/drive/MyDrive/Face_mask_project/data/train/images\n","Images without annotations: 0\n","Annotations without images: 0\n","Folder: /content/drive/MyDrive/Face_mask_project/data/val/images\n","Images without annotations: 0\n","Annotations without images: 0\n","Folder: /content/drive/MyDrive/Face_mask_project/data/test/images\n","Images without annotations: 0\n","Annotations without images: 0\n"]}]},{"cell_type":"code","source":["FOLDERS = [\"train\", \"val\", \"test\"]\n","\n","CLASS_MAP = {\n","    'with_mask': 0,\n","    'without_mask': 1,\n","    'mask_weared_incorrect': 2\n","}\n","\n","# Convert XML to YOLO\n","def convert_xml_to_yolo(xml_file, classes):\n","    tree = ET.parse(xml_file)\n","    root = tree.getroot()\n","    size = root.find('size')\n","    w = int(size.find('width').text)\n","    h = int(size.find('height').text)\n","\n","    yolo_lines = []\n","\n","    for obj in root.findall('object'):\n","        cls_name = obj.find('name').text\n","        if cls_name not in classes:\n","            continue\n","        cls_id = classes[cls_name]\n","\n","        bbox = obj.find('bndbox')\n","        xmin = float(bbox.find('xmin').text)\n","        ymin = float(bbox.find('ymin').text)\n","        xmax = float(bbox.find('xmax').text)\n","        ymax = float(bbox.find('ymax').text)\n","\n","        x_center = (xmin + xmax) / 2.0 / w\n","        y_center = (ymin + ymax) / 2.0 / h\n","        width = (xmax - xmin) / w\n","        height = (ymax - ymin) / h\n","\n","        yolo_lines.append(f\"{cls_id} {x_center:.6f} {y_center:.6f} {width:.6f} {height:.6f}\")\n","\n","    return yolo_lines\n","\n","for folder in FOLDERS:\n","    img_dir = Path(DATA_DIR) / folder\n","    label_dir = img_dir / \"labels\"\n","    label_dir.mkdir(parents=True, exist_ok=True)\n","\n","    xml_dir = Path(DATA_DIR)/ folder / \"annotations\"\n","    xml_files = list(xml_dir.glob(\"*.xml\"))\n","    print(f\"Processing {len(xml_files)} XMLs in {folder} ...\")\n","\n","\n","    for xml_file in xml_files:\n","        yolo_lines = convert_xml_to_yolo(xml_file, CLASS_MAP)\n","        if not yolo_lines:\n","            continue\n","\n","        txt_file = label_dir / f\"{xml_file.stem}.txt\"\n","\n","        with open(txt_file, \"w\") as f:\n","            f.write(\"\\n\".join(yolo_lines))\n","\n","    print(f\"Finished {folder}: labels saved in {label_dir}\")\n","\n","print(\"Finish transfer train/val/test!\")\n","\n","\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6eSqGW4peC0c","executionInfo":{"status":"ok","timestamp":1762193759813,"user_tz":-420,"elapsed":26623,"user":{"displayName":"Bách Vũ Xuân","userId":"10483577199262630046"}},"outputId":"8074c55b-1436-4463-9848-9f7d51aef27e"},"execution_count":24,"outputs":[{"output_type":"stream","name":"stdout","text":["Processing 781 XMLs in train ...\n","Finished train: labels saved in /content/drive/MyDrive/Face_mask_project/data/train/labels\n","Processing 310 XMLs in val ...\n","Finished val: labels saved in /content/drive/MyDrive/Face_mask_project/data/val/labels\n","Processing 161 XMLs in test ...\n","Finished test: labels saved in /content/drive/MyDrive/Face_mask_project/data/test/labels\n","Finish transfer train/val/test!\n"]}]},{"cell_type":"code","source":["TRAIN_DATA_DIR = \"/content/drive/MyDrive/Face_mask_project/data/train\"\n","TRAIN_IMGS_DIR = os.path.join(TRAIN_DATA_DIR, \"images\")\n","TRAIN_LABELS_DIR = os.path.join(TRAIN_DATA_DIR, \"labels\")\n","\n","OVERSAMPLED_DIR = \"/content/drive/MyDrive/Face_mask_project/data/train_oversampled\"\n","OV_IMG = os.path.join(OVERSAMPLED_DIR, \"images\")\n","OV_LBL = os.path.join(OVERSAMPLED_DIR, \"labels\")\n","\n","os.makedirs(OV_IMG, exist_ok=True)\n","os.makedirs(OV_LBL, exist_ok=True)\n","\n","class_images = {0: [], 1: [], 2: []}\n","\n","for lbl_filename in os.listdir(TRAIN_LABELS_DIR):\n","    if not lbl_filename.lower().endswith('.txt'):\n","        continue\n","\n","    lbl_file_path = os.path.join(TRAIN_LABELS_DIR, lbl_filename)\n","\n","    with open(lbl_file_path) as f:\n","        lines = f.readlines()\n","        if not lines:\n","            continue\n","\n","        classes_in_file = set(int(line.split()[0]) for line in lines)\n","\n","        file_stem = os.path.splitext(lbl_filename)[0]\n","        img_filename = f\"{file_stem}.png\"\n","        img_file_path = os.path.join(TRAIN_IMGS_DIR, img_filename)\n","\n","        for cls in classes_in_file:\n","            class_images[cls].append((img_file_path, lbl_file_path))\n","\n","# 3/2/1\n","class_sizes = {cls: len(files) for cls, files in class_images.items()}\n","max_class = max(class_sizes, key=class_sizes.get)\n","base_count = class_sizes[max_class]\n","\n","target_counts = {\n","    max_class: base_count,\n","}\n","other_classes = [c for c in class_images.keys() if c != max_class]\n","target_counts[other_classes[0]] = int(base_count * 2/3)\n","target_counts[other_classes[1]] = int(base_count * 1/3)\n","\n","#Oversampling and copy\n","for cls, files in class_images.items():\n","    n_needed = target_counts[cls]\n","    if len(files) == 0:\n","        continue\n","\n","    n_repeat = n_needed // len(files)\n","    remainder = n_needed % len(files)\n","    all_files = files * n_repeat + random.sample(files, remainder)\n","\n","    for img_file, lbl_file in all_files:\n","        img_filename = os.path.basename(img_file)\n","        dst_img = os.path.join(OV_IMG, img_filename)\n","\n","        lbl_filename = os.path.basename(lbl_file)\n","        dst_lbl = os.path.join(OV_LBL, lbl_filename)\n","\n","        if not os.path.exists(dst_img):\n","            shutil.copy(img_file, dst_img)\n","        if not os.path.exists(dst_lbl):\n","            shutil.copy(lbl_file, dst_lbl)\n","\n","print(\"Dataset oversampled:\", OVERSAMPLED_DIR)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"I5KwQSsIwp8F","executionInfo":{"status":"ok","timestamp":1762230245475,"user_tz":-420,"elapsed":27052,"user":{"displayName":"Bách Vũ Xuân","userId":"10483577199262630046"}},"outputId":"f0f71b12-cdb0-4fa1-e1a5-9f8777342a77"},"execution_count":12,"outputs":[{"output_type":"stream","name":"stdout","text":["Dataset oversampled: /content/drive/MyDrive/Face_mask_project/data/train_oversampled\n"]}]}]}